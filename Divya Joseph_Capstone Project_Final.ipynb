{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67da832c-9892-4e29-9440-f394ceba39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import re,string\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,LayerNormalization\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60a1d39f-86d7-4edf-9a06-273fe45a2ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size: 3725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              question  \\\n",
       "0               hi, how are you doing?   \n",
       "1        i'm fine. how about yourself?   \n",
       "2  i'm pretty good. thanks for asking.   \n",
       "3    no problem. so how have you been?   \n",
       "4     i've been great. what about you?   \n",
       "\n",
       "                                     answer  \n",
       "0             i'm fine. how about yourself?  \n",
       "1       i'm pretty good. thanks for asking.  \n",
       "2         no problem. so how have you been?  \n",
       "3          i've been great. what about you?  \n",
       "4  i've been good. i'm in school right now.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('dialogs.txt', sep='\\t', names=['question', 'answer'])\n",
    "print(f'Dataframe size: {len(df)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfce344-9479-41d1-a18e-dfa12edca7d9",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84966c20-3845-4daa-bbc5-ad905beeb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question tokens']=df['question'].apply(lambda x:len(x.split()))\n",
    "df['answer tokens']=df['answer'].apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e46a5afd-feb7-4537-a02c-fbe3feaf0d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>encoder_inputs</th>\n",
       "      <th>decoder_targets</th>\n",
       "      <th>decoder_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>hi ,  how are you doing ?</td>\n",
       "      <td>i ' m fine .  how about yourself ?  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i ' m fine .  how about yourself ?  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>i ' m fine .  how about yourself ?</td>\n",
       "      <td>i ' m pretty good .  thanks for asking .  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i ' m pretty good .  thanks for asking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i ' m pretty good .  thanks for asking .</td>\n",
       "      <td>no problem .  so how have you been ?  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; no problem .  so how have you been ?  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>no problem .  so how have you been ?</td>\n",
       "      <td>i ' ve been great .  what about you ?  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i ' ve been great .  what about you ? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "      <td>i ' ve been great .  what about you ?</td>\n",
       "      <td>i ' ve been good .  i ' m in school right now ...</td>\n",
       "      <td>&lt;start&gt; i ' ve been good .  i ' m in school ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "      <td>what school do you go to?</td>\n",
       "      <td>i ' ve been good .  i ' m in school right now .</td>\n",
       "      <td>what school do you go to ?  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; what school do you go to ?  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what school do you go to?</td>\n",
       "      <td>i go to pcc.</td>\n",
       "      <td>what school do you go to ?</td>\n",
       "      <td>i go to pcc .  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i go to pcc .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i go to pcc.</td>\n",
       "      <td>do you like it there?</td>\n",
       "      <td>i go to pcc .</td>\n",
       "      <td>do you like it there ?  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; do you like it there ?  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>do you like it there?</td>\n",
       "      <td>it's okay. it's a really big campus.</td>\n",
       "      <td>do you like it there ?</td>\n",
       "      <td>it ' s okay .  it ' s a really big campus .  &lt;...</td>\n",
       "      <td>&lt;start&gt; it ' s okay .  it ' s a really big cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it's okay. it's a really big campus.</td>\n",
       "      <td>good luck with school.</td>\n",
       "      <td>it ' s okay .  it ' s a really big campus .</td>\n",
       "      <td>good luck with school .  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; good luck with school .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   question  \\\n",
       "0                    hi, how are you doing?   \n",
       "1             i'm fine. how about yourself?   \n",
       "2       i'm pretty good. thanks for asking.   \n",
       "3         no problem. so how have you been?   \n",
       "4          i've been great. what about you?   \n",
       "5  i've been good. i'm in school right now.   \n",
       "6                 what school do you go to?   \n",
       "7                              i go to pcc.   \n",
       "8                     do you like it there?   \n",
       "9      it's okay. it's a really big campus.   \n",
       "\n",
       "                                     answer  \\\n",
       "0             i'm fine. how about yourself?   \n",
       "1       i'm pretty good. thanks for asking.   \n",
       "2         no problem. so how have you been?   \n",
       "3          i've been great. what about you?   \n",
       "4  i've been good. i'm in school right now.   \n",
       "5                 what school do you go to?   \n",
       "6                              i go to pcc.   \n",
       "7                     do you like it there?   \n",
       "8      it's okay. it's a really big campus.   \n",
       "9                    good luck with school.   \n",
       "\n",
       "                                     encoder_inputs  \\\n",
       "0                        hi ,  how are you doing ?    \n",
       "1               i ' m fine .  how about yourself ?    \n",
       "2         i ' m pretty good .  thanks for asking .    \n",
       "3             no problem .  so how have you been ?    \n",
       "4            i ' ve been great .  what about you ?    \n",
       "5  i ' ve been good .  i ' m in school right now .    \n",
       "6                       what school do you go to ?    \n",
       "7                                    i go to pcc .    \n",
       "8                           do you like it there ?    \n",
       "9      it ' s okay .  it ' s a really big campus .    \n",
       "\n",
       "                                     decoder_targets  \\\n",
       "0          i ' m fine .  how about yourself ?  <end>   \n",
       "1    i ' m pretty good .  thanks for asking .  <end>   \n",
       "2        no problem .  so how have you been ?  <end>   \n",
       "3       i ' ve been great .  what about you ?  <end>   \n",
       "4  i ' ve been good .  i ' m in school right now ...   \n",
       "5                  what school do you go to ?  <end>   \n",
       "6                               i go to pcc .  <end>   \n",
       "7                      do you like it there ?  <end>   \n",
       "8  it ' s okay .  it ' s a really big campus .  <...   \n",
       "9                     good luck with school .  <end>   \n",
       "\n",
       "                                      decoder_inputs  \n",
       "0  <start> i ' m fine .  how about yourself ?  <end>  \n",
       "1  <start> i ' m pretty good .  thanks for asking...  \n",
       "2  <start> no problem .  so how have you been ?  ...  \n",
       "3  <start> i ' ve been great .  what about you ? ...  \n",
       "4  <start> i ' ve been good .  i ' m in school ri...  \n",
       "5          <start> what school do you go to ?  <end>  \n",
       "6                       <start> i go to pcc .  <end>  \n",
       "7              <start> do you like it there ?  <end>  \n",
       "8  <start> it ' s okay .  it ' s a really big cam...  \n",
       "9             <start> good luck with school .  <end>  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text=re.sub('-',' ',text.lower())\n",
    "    text=re.sub('[.]',' . ',text)\n",
    "    text=re.sub('[1]',' 1 ',text)\n",
    "    text=re.sub('[2]',' 2 ',text)\n",
    "    text=re.sub('[3]',' 3 ',text)\n",
    "    text=re.sub('[4]',' 4 ',text)\n",
    "    text=re.sub('[5]',' 5 ',text)\n",
    "    text=re.sub('[6]',' 6 ',text)\n",
    "    text=re.sub('[7]',' 7 ',text)\n",
    "    text=re.sub('[8]',' 8 ',text)\n",
    "    text=re.sub('[9]',' 9 ',text)\n",
    "    text=re.sub('[0]',' 0 ',text)\n",
    "    text=re.sub('[,]',' , ',text)\n",
    "    text=re.sub('[?]',' ? ',text)\n",
    "    text=re.sub('[!]',' ! ',text)\n",
    "    text=re.sub('[$]',' $ ',text)\n",
    "    text=re.sub('[&]',' & ',text)\n",
    "    text=re.sub('[/]',' / ',text)\n",
    "    text=re.sub('[:]',' : ',text)\n",
    "    text=re.sub('[;]',' ; ',text)\n",
    "    text=re.sub('[*]',' * ',text)\n",
    "    text=re.sub('[\\']',' \\' ',text)\n",
    "    text=re.sub('[\\\"]',' \\\" ',text)\n",
    "    text=re.sub('\\t',' ',text)\n",
    "    return text\n",
    "\n",
    "df.drop(columns=['answer tokens','question tokens'],axis=1,inplace=True)\n",
    "df['encoder_inputs']=df['question'].apply(clean_text)\n",
    "df['decoder_targets']=df['answer'].apply(clean_text)+' <end>'\n",
    "df['decoder_inputs']='<start> '+df['answer'].apply(clean_text)+' <end>'\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "044281b6-3da6-481f-910a-d97c806b2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['encoder input tokens']=df['encoder_inputs'].apply(lambda x:len(x.split()))\n",
    "df['decoder input tokens']=df['decoder_inputs'].apply(lambda x:len(x.split()))\n",
    "df['decoder target tokens']=df['decoder_targets'].apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "952a7a4e-7da8-475b-8709-2171de590958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing: for example ,  if your birth date is january  1  2  ,   1  9  8  7  ,  write  0  1  /  1  2  /  8  7  . \n",
      "Max encoder input length: 27\n",
      "Max decoder input length: 29\n",
      "Max decoder target length: 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder_inputs</th>\n",
       "      <th>decoder_targets</th>\n",
       "      <th>decoder_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi ,  how are you doing ?</td>\n",
       "      <td>i ' m fine .  how about yourself ?  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i ' m fine .  how about yourself ?  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i ' m fine .  how about yourself ?</td>\n",
       "      <td>i ' m pretty good .  thanks for asking .  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i ' m pretty good .  thanks for asking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i ' m pretty good .  thanks for asking .</td>\n",
       "      <td>no problem .  so how have you been ?  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; no problem .  so how have you been ?  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem .  so how have you been ?</td>\n",
       "      <td>i ' ve been great .  what about you ?  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i ' ve been great .  what about you ? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i ' ve been great .  what about you ?</td>\n",
       "      <td>i ' ve been good .  i ' m in school right now ...</td>\n",
       "      <td>&lt;start&gt; i ' ve been good .  i ' m in school ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i ' ve been good .  i ' m in school right now .</td>\n",
       "      <td>what school do you go to ?  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; what school do you go to ?  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what school do you go to ?</td>\n",
       "      <td>i go to pcc .  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i go to pcc .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i go to pcc .</td>\n",
       "      <td>do you like it there ?  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; do you like it there ?  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>do you like it there ?</td>\n",
       "      <td>it ' s okay .  it ' s a really big campus .  &lt;...</td>\n",
       "      <td>&lt;start&gt; it ' s okay .  it ' s a really big cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it ' s okay .  it ' s a really big campus .</td>\n",
       "      <td>good luck with school .  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; good luck with school .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     encoder_inputs  \\\n",
       "0                        hi ,  how are you doing ?    \n",
       "1               i ' m fine .  how about yourself ?    \n",
       "2         i ' m pretty good .  thanks for asking .    \n",
       "3             no problem .  so how have you been ?    \n",
       "4            i ' ve been great .  what about you ?    \n",
       "5  i ' ve been good .  i ' m in school right now .    \n",
       "6                       what school do you go to ?    \n",
       "7                                    i go to pcc .    \n",
       "8                           do you like it there ?    \n",
       "9      it ' s okay .  it ' s a really big campus .    \n",
       "\n",
       "                                     decoder_targets  \\\n",
       "0          i ' m fine .  how about yourself ?  <end>   \n",
       "1    i ' m pretty good .  thanks for asking .  <end>   \n",
       "2        no problem .  so how have you been ?  <end>   \n",
       "3       i ' ve been great .  what about you ?  <end>   \n",
       "4  i ' ve been good .  i ' m in school right now ...   \n",
       "5                  what school do you go to ?  <end>   \n",
       "6                               i go to pcc .  <end>   \n",
       "7                      do you like it there ?  <end>   \n",
       "8  it ' s okay .  it ' s a really big campus .  <...   \n",
       "9                     good luck with school .  <end>   \n",
       "\n",
       "                                      decoder_inputs  \n",
       "0  <start> i ' m fine .  how about yourself ?  <end>  \n",
       "1  <start> i ' m pretty good .  thanks for asking...  \n",
       "2  <start> no problem .  so how have you been ?  ...  \n",
       "3  <start> i ' ve been great .  what about you ? ...  \n",
       "4  <start> i ' ve been good .  i ' m in school ri...  \n",
       "5          <start> what school do you go to ?  <end>  \n",
       "6                       <start> i go to pcc .  <end>  \n",
       "7              <start> do you like it there ?  <end>  \n",
       "8  <start> it ' s okay .  it ' s a really big cam...  \n",
       "9             <start> good luck with school .  <end>  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"After preprocessing: {' '.join(df[df['encoder input tokens'].max()==df['encoder input tokens']]['encoder_inputs'].values.tolist())}\")\n",
    "print(f\"Max encoder input length: {df['encoder input tokens'].max()}\")\n",
    "print(f\"Max decoder input length: {df['decoder input tokens'].max()}\")\n",
    "print(f\"Max decoder target length: {df['decoder target tokens'].max()}\")\n",
    "\n",
    "df.drop(columns=['question','answer','encoder input tokens','decoder input tokens','decoder target tokens'],axis=1,inplace=True)\n",
    "params={\n",
    "    \"vocab_size\":2500,\n",
    "    \"max_sequence_length\":30,\n",
    "    \"learning_rate\":0.008,\n",
    "    \"batch_size\":149,\n",
    "    \"lstm_cells\":256,\n",
    "    \"embedding_dim\":256,\n",
    "    \"buffer_size\":10000\n",
    "}\n",
    "learning_rate=params['learning_rate']\n",
    "batch_size=params['batch_size']\n",
    "embedding_dim=params['embedding_dim']\n",
    "lstm_cells=params['lstm_cells']\n",
    "vocab_size=params['vocab_size']\n",
    "buffer_size=params['buffer_size']\n",
    "max_sequence_length=params['max_sequence_length']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c05ff-0284-4b77-a848-db22c493b916",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8e7d9f6-ee43-4650-b717-45326b9b35a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 2443\n",
      "['', '[UNK]', '<end>', '.', '<start>', \"'\", 'i', '?', 'you', ',', 'the', 'to']\n"
     ]
    }
   ],
   "source": [
    "vectorize_layer=TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    standardize=None,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_sequence_length\n",
    ")\n",
    "vectorize_layer.adapt(df['encoder_inputs']+' '+df['decoder_targets']+' <start> <end>')\n",
    "vocab_size=len(vectorize_layer.get_vocabulary())\n",
    "print(f'Vocab size: {len(vectorize_layer.get_vocabulary())}')\n",
    "print(f'{vectorize_layer.get_vocabulary()[:12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ae7dc51-c059-4b49-b471-fcbecd1ccf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question sentence: hi , how are you ?\n",
      "Question to tokens: [1971    9   45   24    8    7    0    0    0    0]\n",
      "Encoder input shape: (3725, 30)\n",
      "Decoder input shape: (3725, 30)\n",
      "Decoder target shape: (3725, 30)\n"
     ]
    }
   ],
   "source": [
    "def sequences2ids(sequence):\n",
    "    return vectorize_layer(sequence)\n",
    "\n",
    "def ids2sequences(ids):\n",
    "    decode=''\n",
    "    if type(ids)==int:\n",
    "        ids=[ids]\n",
    "    for id in ids:\n",
    "        decode+=vectorize_layer.get_vocabulary()[id]+' '\n",
    "    return decode\n",
    "\n",
    "x=sequences2ids(df['encoder_inputs'])\n",
    "yd=sequences2ids(df['decoder_inputs'])\n",
    "y=sequences2ids(df['decoder_targets'])\n",
    "\n",
    "print(f'Question sentence: hi , how are you ?')\n",
    "print(f'Question to tokens: {sequences2ids(\"hi , how are you ?\")[:10]}')\n",
    "print(f'Encoder input shape: {x.shape}')\n",
    "print(f'Decoder input shape: {yd.shape}')\n",
    "print(f'Decoder target shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "948b7438-063b-4f30-9a24-1d309f9b00e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input: [1971    9   45   24    8  194    7    0    0    0    0    0] ...\n",
      "Decoder input: [  4   6   5  38 646   3  45  41 563   7   2   0] ...\n",
      "Decoder target: [  6   5  38 646   3  45  41 563   7   2   0   0] ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Encoder input: {x[0][:12]} ...')\n",
    "print(f'Decoder input: {yd[0][:12]} ...')    # shifted by one time step of the target as input to decoder is the output of the previous timestep\n",
    "print(f'Decoder target: {y[0][:12]} ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4222f923-82b9-450d-8303-a6896b3c3934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches: 23\n",
      "Number of training data: 3427\n",
      "Number of validation batches: 3\n",
      "Number of validation data: 447\n",
      "Encoder Input shape (with batches): (149, 30)\n",
      "Decoder Input shape (with batches): (149, 30)\n",
      "Target Output shape (with batches): (149, 30)\n"
     ]
    }
   ],
   "source": [
    "data=tf.data.Dataset.from_tensor_slices((x,yd,y))\n",
    "data=data.shuffle(buffer_size)\n",
    "\n",
    "train_data=data.take(int(.9*len(data)))\n",
    "train_data=train_data.cache()\n",
    "train_data=train_data.shuffle(buffer_size)\n",
    "train_data=train_data.batch(batch_size)\n",
    "train_data=train_data.prefetch(tf.data.AUTOTUNE)\n",
    "train_data_iterator=train_data.as_numpy_iterator()\n",
    "\n",
    "val_data=data.skip(int(.9*len(data))).take(int(.1*len(data)))\n",
    "val_data=val_data.batch(batch_size)\n",
    "val_data=val_data.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "_=train_data_iterator.next()\n",
    "print(f'Number of train batches: {len(train_data)}')\n",
    "print(f'Number of training data: {len(train_data)*batch_size}')\n",
    "print(f'Number of validation batches: {len(val_data)}')\n",
    "print(f'Number of validation data: {len(val_data)*batch_size}')\n",
    "print(f'Encoder Input shape (with batches): {_[0].shape}')\n",
    "print(f'Decoder Input shape (with batches): {_[1].shape}')\n",
    "print(f'Target Output shape (with batches): {_[2].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c5c35b-7633-4632-84af-ea8c56d9cec0",
   "metadata": {},
   "source": [
    "## Build Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5067c-8997-4588-9762-06dfcca28cdf",
   "metadata": {},
   "source": [
    "### Build Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e532b35d-226d-4603-8b85-f4eaa293db80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\normalization\\layer_normalization.py:328: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(149, 256), dtype=float32, numpy=\n",
       " array([[ 0.05492529,  0.15266985,  0.04370199, ..., -0.08879866,\n",
       "          0.22202696, -0.37017933],\n",
       "        [ 0.12894006,  0.10224515, -0.06736784, ...,  0.04214153,\n",
       "          0.14457445,  0.04148737],\n",
       "        [-0.24272148,  0.17540565, -0.03193068, ...,  0.0260507 ,\n",
       "         -0.00237005, -0.24734744],\n",
       "        ...,\n",
       "        [ 0.22782134, -0.05090602, -0.30386263, ...,  0.01875009,\n",
       "          0.03926164,  0.14106123],\n",
       "        [-0.09025598,  0.17276779,  0.05515226, ...,  0.10462641,\n",
       "          0.1279037 , -0.16607006],\n",
       "        [ 0.14873864,  0.21059343, -0.25664318, ...,  0.09234403,\n",
       "          0.05701153,  0.0299582 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(149, 256), dtype=float32, numpy=\n",
       " array([[ 0.11698355,  0.2801821 ,  0.08916042, ..., -0.15838134,\n",
       "          0.4478261 , -0.72724086],\n",
       "        [ 0.24675378,  0.18144594, -0.11442132, ...,  0.1114008 ,\n",
       "          0.35674953,  0.08413847],\n",
       "        [-0.6056274 ,  0.32293427, -0.06914635, ...,  0.04740742,\n",
       "         -0.004246  , -0.4543164 ],\n",
       "        ...,\n",
       "        [ 0.49487016, -0.08523113, -0.56065595, ...,  0.04905945,\n",
       "          0.09246615,  0.28529048],\n",
       "        [-0.18876094,  0.31228814,  0.12196576, ...,  0.19092925,\n",
       "          0.2419545 , -0.29498878],\n",
       "        [ 0.28880885,  0.36806208, -0.4510034 , ...,  0.24885537,\n",
       "          0.1299182 ,  0.06052825]], dtype=float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(tf.keras.models.Model):\n",
    "    def __init__(self,units,embedding_dim,vocab_size,*args,**kwargs) -> None:\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.units=units\n",
    "        self.vocab_size=vocab_size\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.embedding=Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            name='encoder_embedding',\n",
    "            mask_zero=True,\n",
    "            embeddings_initializer=tf.keras.initializers.GlorotNormal()\n",
    "        )\n",
    "        self.normalize=LayerNormalization()\n",
    "        self.lstm=LSTM(\n",
    "            units,\n",
    "            dropout=.4,\n",
    "            return_state=True,\n",
    "            return_sequences=True,\n",
    "            name='encoder_lstm',\n",
    "            kernel_initializer=tf.keras.initializers.GlorotNormal()\n",
    "        )\n",
    "    \n",
    "    def call(self,encoder_inputs):\n",
    "        self.inputs=encoder_inputs\n",
    "        x=self.embedding(encoder_inputs)\n",
    "        x=self.normalize(x)\n",
    "        x=Dropout(.4)(x)\n",
    "        encoder_outputs,encoder_state_h,encoder_state_c=self.lstm(x)\n",
    "        self.outputs=[encoder_state_h,encoder_state_c]\n",
    "        return encoder_state_h,encoder_state_c\n",
    "\n",
    "encoder=Encoder(lstm_cells,embedding_dim,vocab_size,name='encoder')\n",
    "encoder.call(_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e0ac94-63a9-40ea-8370-0ccbdf2cd5d1",
   "metadata": {},
   "source": [
    "#### Build Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0701a63-d6ec-43c7-ae8c-aad16a14b6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 30, 2443), dtype=float32, numpy=\n",
       "array([[[1.24806713e-04, 7.05349725e-04, 1.32141295e-05, ...,\n",
       "         1.02151387e-06, 5.42894668e-05, 2.19893845e-04],\n",
       "        [3.68122819e-05, 7.15220987e-04, 9.15452139e-04, ...,\n",
       "         2.28956978e-05, 2.40401223e-05, 2.93040823e-04],\n",
       "        [5.52982383e-05, 4.67358419e-04, 2.23151772e-04, ...,\n",
       "         5.88133735e-05, 4.65654666e-05, 4.72281157e-04],\n",
       "        ...,\n",
       "        [3.37879901e-05, 3.59287951e-04, 6.96842762e-05, ...,\n",
       "         2.37563181e-05, 4.74902590e-05, 2.99803971e-04],\n",
       "        [3.37879901e-05, 3.59287951e-04, 6.96842762e-05, ...,\n",
       "         2.37563181e-05, 4.74902590e-05, 2.99803971e-04],\n",
       "        [3.37879901e-05, 3.59287951e-04, 6.96842762e-05, ...,\n",
       "         2.37563181e-05, 4.74902590e-05, 2.99803971e-04]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(tf.keras.models.Model):\n",
    "    def __init__(self,units,embedding_dim,vocab_size,*args,**kwargs) -> None:\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.units=units\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.vocab_size=vocab_size\n",
    "        self.embedding=Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            name='decoder_embedding',\n",
    "            mask_zero=True,\n",
    "            embeddings_initializer=tf.keras.initializers.HeNormal()\n",
    "        )\n",
    "        self.normalize=LayerNormalization()\n",
    "        self.lstm=LSTM(\n",
    "            units,\n",
    "            dropout=.4,\n",
    "            return_state=True,\n",
    "            return_sequences=True,\n",
    "            name='decoder_lstm',\n",
    "            kernel_initializer=tf.keras.initializers.HeNormal()\n",
    "        )\n",
    "        self.fc=Dense(\n",
    "            vocab_size,\n",
    "            activation='softmax',\n",
    "            name='decoder_dense',\n",
    "            kernel_initializer=tf.keras.initializers.HeNormal()\n",
    "        )\n",
    "    \n",
    "    def call(self,decoder_inputs,encoder_states):\n",
    "        x=self.embedding(decoder_inputs)\n",
    "        x=self.normalize(x)\n",
    "        x=Dropout(.4)(x)\n",
    "        x,decoder_state_h,decoder_state_c=self.lstm(x,initial_state=encoder_states)\n",
    "        x=self.normalize(x)\n",
    "        x=Dropout(.4)(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "decoder=Decoder(lstm_cells,embedding_dim,vocab_size,name='decoder')\n",
    "decoder(_[1][:1],encoder(_[0][:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63884dbb-e1fa-4508-b171-58b40302b076",
   "metadata": {},
   "source": [
    "### Build Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655db984-7e17-4a08-b127-4c77e93873c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBotTrainer(tf.keras.models.Model):\n",
    "    def __init__(self,encoder,decoder,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "\n",
    "    def loss_fn(self,y_true,y_pred):\n",
    "        loss=self.loss(y_true,y_pred)\n",
    "        mask=tf.math.logical_not(tf.math.equal(y_true,0))\n",
    "        mask=tf.cast(mask,dtype=loss.dtype)\n",
    "        loss*=mask\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    def accuracy_fn(self,y_true,y_pred):\n",
    "        pred_values = tf.cast(tf.argmax(y_pred, axis=-1), dtype='int64')\n",
    "        correct = tf.cast(tf.equal(y_true, pred_values), dtype='float64')\n",
    "        mask = tf.cast(tf.greater(y_true, 0), dtype='float64')\n",
    "        n_correct = tf.keras.backend.sum(mask * correct)\n",
    "        n_total = tf.keras.backend.sum(mask)\n",
    "        return n_correct / n_total\n",
    "\n",
    "    def call(self,inputs):\n",
    "        encoder_inputs,decoder_inputs=inputs\n",
    "        encoder_states=self.encoder(encoder_inputs)\n",
    "        return self.decoder(decoder_inputs,encoder_states)\n",
    "\n",
    "    def train_step(self,batch):\n",
    "        encoder_inputs,decoder_inputs,y=batch\n",
    "        with tf.GradientTape() as tape:\n",
    "            encoder_states=self.encoder(encoder_inputs,training=True)\n",
    "            y_pred=self.decoder(decoder_inputs,encoder_states,training=True)\n",
    "            loss=self.loss_fn(y,y_pred)\n",
    "            acc=self.accuracy_fn(y,y_pred)\n",
    "\n",
    "        variables=self.encoder.trainable_variables+self.decoder.trainable_variables\n",
    "        grads=tape.gradient(loss,variables)\n",
    "        self.optimizer.apply_gradients(zip(grads,variables))\n",
    "        metrics={'loss':loss,'accuracy':acc}\n",
    "        return metrics\n",
    "    \n",
    "    def test_step(self,batch):\n",
    "        encoder_inputs,decoder_inputs,y=batch\n",
    "        encoder_states=self.encoder(encoder_inputs,training=True)\n",
    "        y_pred=self.decoder(decoder_inputs,encoder_states,training=True)\n",
    "        loss=self.loss_fn(y,y_pred)\n",
    "        acc=self.accuracy_fn(y,y_pred)\n",
    "        metrics={'loss':loss,'accuracy':acc}\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af99e341-d01b-410a-9f38-f2b19575598e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(149, 30, 2443), dtype=float32, numpy=\n",
       "array([[[1.24806713e-04, 7.05349725e-04, 1.32141295e-05, ...,\n",
       "         1.02151387e-06, 5.42894668e-05, 2.19893845e-04],\n",
       "        [3.68122819e-05, 7.15220987e-04, 9.15452139e-04, ...,\n",
       "         2.28956978e-05, 2.40401223e-05, 2.93040823e-04],\n",
       "        [5.52982383e-05, 4.67358419e-04, 2.23151772e-04, ...,\n",
       "         5.88133735e-05, 4.65654666e-05, 4.72281157e-04],\n",
       "        ...,\n",
       "        [3.37879901e-05, 3.59287951e-04, 6.96842762e-05, ...,\n",
       "         2.37563181e-05, 4.74902590e-05, 2.99803971e-04],\n",
       "        [3.37879901e-05, 3.59287951e-04, 6.96842762e-05, ...,\n",
       "         2.37563181e-05, 4.74902590e-05, 2.99803971e-04],\n",
       "        [3.37879901e-05, 3.59287951e-04, 6.96842762e-05, ...,\n",
       "         2.37563181e-05, 4.74902590e-05, 2.99803971e-04]],\n",
       "\n",
       "       [[2.43271970e-05, 6.29221671e-04, 1.26887471e-05, ...,\n",
       "         1.30482283e-06, 9.33110932e-05, 2.04422380e-04],\n",
       "        [4.01568905e-05, 1.62811790e-04, 4.06391948e-04, ...,\n",
       "         2.09070004e-05, 2.11285762e-04, 2.12277941e-04],\n",
       "        [1.63111676e-04, 1.03797989e-04, 2.96981947e-04, ...,\n",
       "         8.93366814e-06, 1.68570477e-04, 2.67907482e-04],\n",
       "        ...,\n",
       "        [4.12845839e-06, 7.59104441e-05, 1.67965700e-04, ...,\n",
       "         1.84567161e-05, 2.89920899e-05, 3.30899493e-05],\n",
       "        [4.12845839e-06, 7.59104441e-05, 1.67965700e-04, ...,\n",
       "         1.84567161e-05, 2.89920899e-05, 3.30899493e-05],\n",
       "        [4.12845839e-06, 7.59104441e-05, 1.67965700e-04, ...,\n",
       "         1.84567161e-05, 2.89920899e-05, 3.30899493e-05]],\n",
       "\n",
       "       [[7.43060809e-05, 7.56362162e-04, 3.16590049e-05, ...,\n",
       "         3.16742126e-06, 1.16384435e-04, 1.81366602e-04],\n",
       "        [9.68896347e-05, 1.31113385e-03, 1.48723839e-05, ...,\n",
       "         8.28850352e-06, 5.86920942e-05, 1.89717510e-04],\n",
       "        [1.67145845e-04, 2.76035105e-04, 4.34774120e-05, ...,\n",
       "         7.75704666e-06, 2.00712937e-04, 1.70053012e-04],\n",
       "        ...,\n",
       "        [7.25715745e-06, 1.02952239e-04, 4.68642393e-05, ...,\n",
       "         1.10734236e-05, 2.92592333e-04, 6.31092189e-05],\n",
       "        [7.25715745e-06, 1.02952239e-04, 4.68642393e-05, ...,\n",
       "         1.10734236e-05, 2.92592333e-04, 6.31092189e-05],\n",
       "        [7.25715745e-06, 1.02952239e-04, 4.68642393e-05, ...,\n",
       "         1.10734236e-05, 2.92592333e-04, 6.31092189e-05]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[3.24115645e-05, 6.27962465e-04, 1.01769019e-05, ...,\n",
       "         3.00788452e-06, 5.78692816e-05, 2.44259340e-04],\n",
       "        [1.37619849e-04, 3.08081042e-04, 2.08913625e-04, ...,\n",
       "         5.57162411e-06, 4.62439231e-04, 1.84235614e-04],\n",
       "        [1.70120456e-05, 6.24422973e-05, 2.27439654e-04, ...,\n",
       "         3.51908307e-06, 3.58095480e-04, 5.22034934e-05],\n",
       "        ...,\n",
       "        [2.09389782e-05, 5.52200254e-05, 2.61032037e-05, ...,\n",
       "         1.36822928e-05, 5.98104925e-05, 3.08954841e-05],\n",
       "        [2.09389782e-05, 5.52200254e-05, 2.61032037e-05, ...,\n",
       "         1.36822928e-05, 5.98104925e-05, 3.08954841e-05],\n",
       "        [2.09389782e-05, 5.52200254e-05, 2.61032037e-05, ...,\n",
       "         1.36822928e-05, 5.98104925e-05, 3.08954841e-05]],\n",
       "\n",
       "       [[6.19507773e-05, 1.24545780e-03, 3.18475395e-05, ...,\n",
       "         1.22463655e-06, 1.17242700e-04, 1.09212779e-04],\n",
       "        [3.39541439e-04, 1.92036532e-04, 1.65235135e-04, ...,\n",
       "         3.04174682e-06, 1.64457815e-04, 3.57687520e-03],\n",
       "        [3.05982539e-04, 1.52975816e-04, 3.52477597e-04, ...,\n",
       "         5.91552416e-05, 3.21286170e-05, 4.62478376e-04],\n",
       "        ...,\n",
       "        [5.93558325e-05, 1.25446575e-04, 3.37294274e-04, ...,\n",
       "         6.25355315e-05, 8.11322898e-05, 1.47306811e-04],\n",
       "        [5.93558325e-05, 1.25446575e-04, 3.37294274e-04, ...,\n",
       "         6.25355315e-05, 8.11322898e-05, 1.47306811e-04],\n",
       "        [5.93558325e-05, 1.25446575e-04, 3.37294274e-04, ...,\n",
       "         6.25355315e-05, 8.11322898e-05, 1.47306811e-04]],\n",
       "\n",
       "       [[4.12690497e-05, 1.95661141e-03, 3.04083751e-05, ...,\n",
       "         9.98707128e-06, 4.83089098e-05, 1.03512873e-04],\n",
       "        [1.56144393e-04, 5.23731462e-04, 3.35066346e-04, ...,\n",
       "         1.18869639e-05, 4.98491689e-04, 1.10836780e-04],\n",
       "        [3.58557358e-04, 2.69519514e-04, 2.60914705e-04, ...,\n",
       "         1.84240955e-04, 1.36650226e-04, 2.33684186e-04],\n",
       "        ...,\n",
       "        [1.36369281e-05, 4.73279179e-05, 1.36413364e-04, ...,\n",
       "         4.40602525e-05, 6.33019226e-05, 5.99703963e-05],\n",
       "        [1.36369281e-05, 4.73279179e-05, 1.36413364e-04, ...,\n",
       "         4.40602525e-05, 6.33019226e-05, 5.99703963e-05],\n",
       "        [1.36369281e-05, 4.73279179e-05, 1.36413364e-04, ...,\n",
       "         4.40602525e-05, 6.33019226e-05, 5.99703963e-05]]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=ChatBotTrainer(encoder,decoder,name='chatbot_trainer')\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    weighted_metrics=['loss','accuracy']\n",
    ")\n",
    "model(_[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc9ae23-a737-4d90-b114-bfb10ca49e80",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfc88918-bc54-4107-83d2-ab8297a8f603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.5512\n",
      "Epoch 1: val_loss improved from inf to 0.72636, saving model to ckpt\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 66s 3s/step - loss: 0.5259 - accuracy: 0.5503 - val_loss: 0.7264 - val_accuracy: 0.4993\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.5537\n",
      "Epoch 2: val_loss improved from 0.72636 to 0.55080, saving model to ckpt\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 27s 1s/step - loss: 0.5175 - accuracy: 0.5522 - val_loss: 0.5508 - val_accuracy: 0.5560\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5147 - accuracy: 0.5574\n",
      "Epoch 3: val_loss did not improve from 0.55080\n",
      "23/23 [==============================] - 21s 902ms/step - loss: 0.5158 - accuracy: 0.5565 - val_loss: 0.6149 - val_accuracy: 0.5605\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5098 - accuracy: 0.5592\n",
      "Epoch 4: val_loss did not improve from 0.55080\n",
      "23/23 [==============================] - 20s 864ms/step - loss: 0.5115 - accuracy: 0.5571 - val_loss: 0.6153 - val_accuracy: 0.5196\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5033 - accuracy: 0.5628\n",
      "Epoch 5: val_loss did not improve from 0.55080\n",
      "23/23 [==============================] - 20s 868ms/step - loss: 0.5024 - accuracy: 0.5624 - val_loss: 0.6298 - val_accuracy: 0.5284\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.5680\n",
      "Epoch 6: val_loss did not improve from 0.55080\n",
      "23/23 [==============================] - 20s 876ms/step - loss: 0.4983 - accuracy: 0.5657 - val_loss: 0.6302 - val_accuracy: 0.5394\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.5723\n",
      "Epoch 7: val_loss did not improve from 0.55080\n",
      "23/23 [==============================] - 20s 883ms/step - loss: 0.4931 - accuracy: 0.5712 - val_loss: 0.6051 - val_accuracy: 0.5647\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4885 - accuracy: 0.5727\n",
      "Epoch 8: val_loss did not improve from 0.55080\n",
      "23/23 [==============================] - 20s 887ms/step - loss: 0.4899 - accuracy: 0.5717 - val_loss: 0.5960 - val_accuracy: 0.5302\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.5773\n",
      "Epoch 9: val_loss did not improve from 0.55080\n",
      "23/23 [==============================] - 20s 862ms/step - loss: 0.4844 - accuracy: 0.5766 - val_loss: 0.5516 - val_accuracy: 0.5702\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4767 - accuracy: 0.5793\n",
      "Epoch 10: val_loss did not improve from 0.55080\n",
      "23/23 [==============================] - 20s 858ms/step - loss: 0.4768 - accuracy: 0.5794 - val_loss: 0.7089 - val_accuracy: 0.5461\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.5845\n",
      "Epoch 11: val_loss improved from 0.55080 to 0.54868, saving model to ckpt\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 32s 1s/step - loss: 0.4757 - accuracy: 0.5840 - val_loss: 0.5487 - val_accuracy: 0.5927\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4692 - accuracy: 0.5849 \n",
      "Epoch 12: val_loss improved from 0.54868 to 0.50263, saving model to ckpt\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 625s 28s/step - loss: 0.4680 - accuracy: 0.5855 - val_loss: 0.5026 - val_accuracy: 0.6120\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4651 - accuracy: 0.5884\n",
      "Epoch 13: val_loss did not improve from 0.50263\n",
      "23/23 [==============================] - 16s 695ms/step - loss: 0.4639 - accuracy: 0.5892 - val_loss: 0.6210 - val_accuracy: 0.5391\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4591 - accuracy: 0.5949\n",
      "Epoch 14: val_loss improved from 0.50263 to 0.48408, saving model to ckpt\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 31s 1s/step - loss: 0.4594 - accuracy: 0.5944 - val_loss: 0.4841 - val_accuracy: 0.5968\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.5968\n",
      "Epoch 15: val_loss did not improve from 0.48408\n",
      "23/23 [==============================] - 19s 813ms/step - loss: 0.4529 - accuracy: 0.5967 - val_loss: 0.5685 - val_accuracy: 0.5877\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.5949\n",
      "Epoch 16: val_loss did not improve from 0.48408\n",
      "23/23 [==============================] - 18s 772ms/step - loss: 0.4533 - accuracy: 0.5951 - val_loss: 0.5466 - val_accuracy: 0.5750\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4479 - accuracy: 0.5981\n",
      "Epoch 17: val_loss did not improve from 0.48408\n",
      "23/23 [==============================] - 18s 769ms/step - loss: 0.4476 - accuracy: 0.5980 - val_loss: 0.5045 - val_accuracy: 0.5749\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.5994\n",
      "Epoch 18: val_loss improved from 0.48408 to 0.45880, saving model to ckpt\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 29s 1s/step - loss: 0.4468 - accuracy: 0.5992 - val_loss: 0.4588 - val_accuracy: 0.6072\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4440 - accuracy: 0.6006\n",
      "Epoch 19: val_loss did not improve from 0.45880\n",
      "23/23 [==============================] - 20s 863ms/step - loss: 0.4460 - accuracy: 0.5997 - val_loss: 0.4683 - val_accuracy: 0.6055\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.6031\n",
      "Epoch 20: val_loss did not improve from 0.45880\n",
      "23/23 [==============================] - 20s 851ms/step - loss: 0.4408 - accuracy: 0.6032 - val_loss: 0.5043 - val_accuracy: 0.5877\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.6089\n",
      "Epoch 21: val_loss did not improve from 0.45880\n",
      "23/23 [==============================] - 20s 859ms/step - loss: 0.4356 - accuracy: 0.6081 - val_loss: 0.4799 - val_accuracy: 0.6347\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.6121\n",
      "Epoch 22: val_loss did not improve from 0.45880\n",
      "23/23 [==============================] - 22s 958ms/step - loss: 0.4353 - accuracy: 0.6128 - val_loss: 0.4733 - val_accuracy: 0.6280\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4288 - accuracy: 0.6105\n",
      "Epoch 23: val_loss did not improve from 0.45880\n",
      "23/23 [==============================] - 21s 897ms/step - loss: 0.4299 - accuracy: 0.6098 - val_loss: 0.5175 - val_accuracy: 0.5882\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4253 - accuracy: 0.6164\n",
      "Epoch 24: val_loss did not improve from 0.45880\n",
      "23/23 [==============================] - 20s 870ms/step - loss: 0.4262 - accuracy: 0.6161 - val_loss: 0.5318 - val_accuracy: 0.5788\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.6137\n",
      "Epoch 25: val_loss improved from 0.45880 to 0.41716, saving model to ckpt\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 32s 1s/step - loss: 0.4250 - accuracy: 0.6143 - val_loss: 0.4172 - val_accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    train_data,\n",
    "    epochs=25,\n",
    "    validation_data=val_data,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "        tf.keras.callbacks.ModelCheckpoint('ckpt',verbose=1,save_best_only=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f815a8c-a3f3-4adc-b42a-aaa75f81d458",
   "metadata": {},
   "source": [
    "## Visualize Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ed02c-287f-495b-8cfe-8a599372296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(20,5))\n",
    "ax[0].plot(history.history['loss'],label='loss',c='red')\n",
    "ax[0].plot(history.history['val_loss'],label='val_loss',c = 'blue')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[0].set_title('Loss Metrics')\n",
    "ax[1].set_title('Accuracy Metrics')\n",
    "ax[1].plot(history.history['accuracy'],label='accuracy')\n",
    "ax[1].plot(history.history['val_accuracy'],label='val_accuracy')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c49880-cc9e-41be-a0f3-ec2f252e5793",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f96e7cf9-1b8f-4a42-8d9b-ba589c6d8a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('ckpt')\n",
    "model.save('models',save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3789af16-503f-49c5-a5b3-94a05397bde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder layers:\n",
      "<keras.src.layers.core.embedding.Embedding object at 0x000001F968C8DFD0>\n",
      "<keras.src.layers.normalization.layer_normalization.LayerNormalization object at 0x000001F9521CE490>\n",
      "<keras.src.layers.rnn.lstm.LSTM object at 0x000001F96ED55CD0>\n",
      "---------------------\n",
      "Decoder layers: \n",
      "<keras.src.layers.core.embedding.Embedding object at 0x000001F96ED49710>\n",
      "<keras.src.layers.normalization.layer_normalization.LayerNormalization object at 0x000001F96ED48050>\n",
      "<keras.src.layers.rnn.lstm.LSTM object at 0x000001F96ED110D0>\n",
      "<keras.src.layers.core.dense.Dense object at 0x000001F96ED08750>\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for idx,i in enumerate(model.layers):\n",
    "    print('Encoder layers:' if idx==0 else 'Decoder layers: ')\n",
    "    for j in i.layers:\n",
    "        print(j)\n",
    "    print('---------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82a4ac1-72e6-4d70-9af8-91b9ce90fefc",
   "metadata": {},
   "source": [
    "## Create Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d4fb228-11c4-40ad-b7e6-20f67ff154c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"chatbot_encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " encoder_embedding (Embeddi  (None, None, 256)         625408    \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " layer_normalization (Layer  (None, None, 256)         512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " encoder_lstm (LSTM)         [(None, None, 256),       525312    \n",
      "                              (None, 256),                       \n",
      "                              (None, 256)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1151232 (4.39 MB)\n",
      "Trainable params: 1151232 (4.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"chatbot_decoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " decoder_embedding (Embeddi  (None, None, 256)            625408    ['input_12[0][0]']            \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, None, 256)            512       ['decoder_embedding[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)       [(None, 256)]                0         []                            \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)       [(None, 256)]                0         []                            \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)         [(None, None, 256),          525312    ['layer_normalization[1][0]', \n",
      "                              (None, 256),                           'input_10[0][0]',            \n",
      "                              (None, 256)]                           'input_11[0][0]']            \n",
      "                                                                                                  \n",
      " decoder_dense (Dense)       (None, None, 2443)           627851    ['decoder_lstm[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1779083 (6.79 MB)\n",
      "Trainable params: 1779083 (6.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class ChatBot(tf.keras.models.Model):\n",
    "    def __init__(self,base_encoder,base_decoder,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.encoder,self.decoder=self.build_inference_model(base_encoder,base_decoder)\n",
    "\n",
    "    def build_inference_model(self,base_encoder,base_decoder):\n",
    "        encoder_inputs=tf.keras.Input(shape=(None,))\n",
    "        x=base_encoder.layers[0](encoder_inputs)\n",
    "        x=base_encoder.layers[1](x)\n",
    "        x,encoder_state_h,encoder_state_c=base_encoder.layers[2](x)\n",
    "        encoder=tf.keras.models.Model(inputs=encoder_inputs,outputs=[encoder_state_h,encoder_state_c],name='chatbot_encoder')\n",
    "\n",
    "        decoder_input_state_h=tf.keras.Input(shape=(lstm_cells,))\n",
    "        decoder_input_state_c=tf.keras.Input(shape=(lstm_cells,))\n",
    "        decoder_inputs=tf.keras.Input(shape=(None,))\n",
    "        x=base_decoder.layers[0](decoder_inputs)\n",
    "        x=base_encoder.layers[1](x)\n",
    "        x,decoder_state_h,decoder_state_c=base_decoder.layers[2](x,initial_state=[decoder_input_state_h,decoder_input_state_c])\n",
    "        decoder_outputs=base_decoder.layers[-1](x)\n",
    "        decoder=tf.keras.models.Model(\n",
    "            inputs=[decoder_inputs,[decoder_input_state_h,decoder_input_state_c]],\n",
    "            outputs=[decoder_outputs,[decoder_state_h,decoder_state_c]],name='chatbot_decoder'\n",
    "        )\n",
    "        return encoder,decoder\n",
    "\n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "\n",
    "    def softmax(self,z):\n",
    "        return np.exp(z)/sum(np.exp(z))\n",
    "\n",
    "    def sample(self,conditional_probability,temperature=0.5):\n",
    "        conditional_probability = np.asarray(conditional_probability).astype(\"float64\")\n",
    "        conditional_probability = np.log(conditional_probability) / temperature\n",
    "        reweighted_conditional_probability = self.softmax(conditional_probability)\n",
    "        probas = np.random.multinomial(1, reweighted_conditional_probability, 1)\n",
    "        return np.argmax(probas)\n",
    "\n",
    "    def preprocess(self,text):\n",
    "        text=clean_text(text)\n",
    "        seq=np.zeros((1,max_sequence_length),dtype=np.int32)\n",
    "        for i,word in enumerate(text.split()):\n",
    "            seq[:,i]=sequences2ids(word).numpy()[0]\n",
    "        return seq\n",
    "    \n",
    "    def postprocess(self,text):\n",
    "        text=re.sub(' - ','-',text.lower())\n",
    "        text=re.sub(' [.] ','. ',text)\n",
    "        text=re.sub(' [1] ','1',text)\n",
    "        text=re.sub(' [2] ','2',text)\n",
    "        text=re.sub(' [3] ','3',text)\n",
    "        text=re.sub(' [4] ','4',text)\n",
    "        text=re.sub(' [5] ','5',text)\n",
    "        text=re.sub(' [6] ','6',text)\n",
    "        text=re.sub(' [7] ','7',text)\n",
    "        text=re.sub(' [8] ','8',text)\n",
    "        text=re.sub(' [9] ','9',text)\n",
    "        text=re.sub(' [0] ','0',text)\n",
    "        text=re.sub(' [,] ',', ',text)\n",
    "        text=re.sub(' [?] ','? ',text)\n",
    "        text=re.sub(' [!] ','! ',text)\n",
    "        text=re.sub(' [$] ','$ ',text)\n",
    "        text=re.sub(' [&] ','& ',text)\n",
    "        text=re.sub(' [/] ','/ ',text)\n",
    "        text=re.sub(' [:] ',': ',text)\n",
    "        text=re.sub(' [;] ','; ',text)\n",
    "        text=re.sub(' [*] ','* ',text)\n",
    "        text=re.sub(' [\\'] ','\\'',text)\n",
    "        text=re.sub(' [\\\"] ','\\\"',text)\n",
    "        return text\n",
    "\n",
    "    def call(self,text,config=None):\n",
    "        input_seq=self.preprocess(text)\n",
    "        states=self.encoder(input_seq,training=False)\n",
    "        target_seq=np.zeros((1,1))\n",
    "        target_seq[:,:]=sequences2ids(['<start>']).numpy()[0][0]\n",
    "        stop_condition=False\n",
    "        decoded=[]\n",
    "        while not stop_condition:\n",
    "            decoder_outputs,new_states=self.decoder([target_seq,states],training=False)\n",
    "#             index=tf.argmax(decoder_outputs[:,-1,:],axis=-1).numpy().item()\n",
    "            index=self.sample(decoder_outputs[0,0,:]).item()\n",
    "            word=ids2sequences([index])\n",
    "            if word=='<end> ' or len(decoded)>=max_sequence_length:\n",
    "                stop_condition=True\n",
    "            else:\n",
    "                decoded.append(index)\n",
    "                target_seq=np.zeros((1,1))\n",
    "                target_seq[:,:]=index\n",
    "                states=new_states\n",
    "        return self.postprocess(ids2sequences(decoded))\n",
    "\n",
    "chatbot=ChatBot(model.encoder,model.decoder,name='chatbot')\n",
    "chatbot.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef82ed4-15c9-4d38-9451-5a7e2f668c4a",
   "metadata": {},
   "source": [
    "### Time to chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25b7200c-3655-4f1e-bc60-f5d493b404dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_conversation(texts):\n",
    "    for text in texts:\n",
    "        print(f'You: {text}')\n",
    "        print(f'Bot: {chatbot(text)}')\n",
    "        print('========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4501c34-5b40-4596-9033-09891420ccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hi\n",
      "Bot: they don't know. \n",
      "========================\n",
      "You: do yo know me?\n",
      "Bot: no. they said there's the only candidate that i've. \n",
      "========================\n",
      "You: what is your name?\n",
      "Bot: i'm going to give the sheets. \n",
      "========================\n",
      "You: you are bot?\n",
      "Bot: i don't know. i'm not sure. \n",
      "========================\n",
      "You: hi, how are you doing?\n",
      "Bot: i've been working too. \n",
      "========================\n",
      "You: i'm pretty good. thanks for asking.\n",
      "Bot: no, i think i'll make a sandwich. \n",
      "========================\n",
      "You: Don't ever be in a hurry\n",
      "Bot: it's a little bitter, but i don't think she's given out that many. \n",
      "========================\n",
      "You: I'm gonna put some dirt in your eye \n",
      "Bot: that's a good question. \n",
      "========================\n",
      "You: You're trash \n",
      "Bot: i'm sorry. i'm not hungry. \n",
      "========================\n",
      "You: I've read all your research on nano-technology \n",
      "Bot: i've been really busy. i love to eat the hot dogs. \n",
      "========================\n",
      "You: You want forgiveness? Get religion\n",
      "Bot: i'll get a new mattress. \n",
      "========================\n",
      "You: While you're using the bathroom, i'll order some food.\n",
      "Bot: don't order a good idea. i'll order for your invitation. \n",
      "========================\n",
      "You: Wow! that's terrible.\n",
      "Bot: never park the car under the tree. \n",
      "========================\n",
      "You: We'll be here forever.\n",
      "Bot: we'll see the collision if it happen. \n",
      "========================\n",
      "You: I need something that's reliable.\n",
      "Bot: you need a car with low mileage. \n",
      "========================\n",
      "You: A speeding car ran a red light, killing the girl.\n",
      "Bot: what happened? \n",
      "========================\n",
      "You: Tomorrow we'll have rice and fish for lunch.\n",
      "Bot: i'll see the food and the cut heals. \n",
      "========================\n",
      "You: I like this restaurant because they give you free bread.\n",
      "Bot: well, you're right. you left the burner on. \n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "print_conversation([\n",
    "    'hi',\n",
    "    'do yo know me?',\n",
    "    'what is your name?',\n",
    "    'you are bot?',\n",
    "    'hi, how are you doing?',\n",
    "    \"i'm pretty good. thanks for asking.\",\n",
    "    \"Don't ever be in a hurry\",\n",
    "    '''I'm gonna put some dirt in your eye ''',\n",
    "    '''You're trash ''',\n",
    "    '''I've read all your research on nano-technology ''',\n",
    "    '''You want forgiveness? Get religion''',\n",
    "    '''While you're using the bathroom, i'll order some food.''',\n",
    "    '''Wow! that's terrible.''',\n",
    "    '''We'll be here forever.''',\n",
    "    '''I need something that's reliable.''',\n",
    "    '''A speeding car ran a red light, killing the girl.''',\n",
    "    '''Tomorrow we'll have rice and fish for lunch.''',\n",
    "    '''I like this restaurant because they give you free bread.'''\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5235c17c-bcc3-44b6-b28b-5dbe4d198640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22069757-cd8b-4a11-a4a2-066e8649b52e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
